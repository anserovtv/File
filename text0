#RandomForestClassifier
import seaborn  as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
 
 
doc0 = "Данные материалы содержат некоторые рекомендации и соответствующий инструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальных данных при проведении линейного и параллельного экспериментов в ВКР"

doc1 = "Данныематериалы содержат некоторые рекомендации и соответствующий инструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальных данных при проведении линейного и параллельного экспериментов в ВКР"

doc2 = "Данныематериалы содержатнекоторые рекомендации и соответствующий инструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальных данных при проведении линейного и параллельного экспериментов в ВКР"

doc3 = "Данные материалы содержат некоторые рекомендацииисоответствующийинструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальных данных при проведении линейного и параллельного экспериментов в ВКР"

doc4 = "Данныематериалы содержат некоторые рекомендации и соответствующийинструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальных данных при проведении линейного и параллельного экспериментов в ВКР"

texts = [doc0, doc1, doc2, doc3,doc4]

texts_labels = [1, 0, 0, 0, 0]
print(texts[0])
text_clf = Pipeline([
                     ('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier())
                     ])
 
text_clf.fit(texts, texts_labels)
X = texts
y = texts_labels
res = text_clf.predict(X)
print(res)  # [1]

import lime
import sklearn
import numpy as np
import sklearn
import sklearn.ensemble
import sklearn.metrics
from __future__ import print_function
from lime import lime_text
from sklearn. pipeline import make_pipeline
c = text_clf
print(c.predict_proba([texts[0]]))
from lime.lime_text import LimeTextExplainer
class_names  =  ['ноль',  'один']
explainer = LimeTextExplainer(class_names=class_names)
idx = 0
exp = explainer.explain_instance(X[idx], c.predict_proba, num_features=10)
print('Document id: %d' % idx)
print('Probability(один) =', c.predict_proba([X[idx]])[0,1])
print('True class: %s'% class_names[y[idx]])
exp.as_list()
%matplotlib inline
fig = exp.as_pyplot_figure()
exp.show_in_notebook(text=False)
exp.show_in_notebook(text=True)

import lime
import sklearn
import numpy as np
import sklearn
import sklearn.ensemble
import sklearn.metrics
from __future__ import print_function
from lime import lime_text
from sklearn. pipeline import make_pipeline
c = text_clf
print(c.predict_proba([texts[0]]))
from lime.lime_text import LimeTextExplainer
class_names  =  ['ноль',  'один']
explainer = LimeTextExplainer(class_names=class_names)
idx = 0
exp = explainer.explain_instance(X[idx], c.predict_proba, num_features=10)
print('Document id: %d' % idx)
print('Probability(один) =', c.predict_proba([X[idx]])[0,1])
print('True class: %s'% class_names[y[idx]])
exp.as_list()
%matplotlib inline
fig = exp.as_pyplot_figure()
exp.show_in_notebook(text=False)
idx = 2
print(texts[2])
exp = explainer.explain_instance(X[idx], c.predict_proba, num_features=4)
print('Document id: %d' % idx)
print('Probability(один) =', c.predict_proba([X[idx]])[0,1])
print('True class: %s'% class_names[y[idx]])
exp.as_list()
%matplotlib inline
fig = exp.as_pyplot_figure()

exp.show_in_notebook(text=False)
X2 = 'Данныематериалысодержат некоторые рекомендацииисоответствующийинструментарий (в форме кодов R) для выполнения статистического анализа и визуализации экспериментальныхданных при проведении линейного и параллельногоэкспериментов в ВКР'

explainer = LimeTextExplainer(class_names=class_names)
exp = explainer.explain_instance(X2, c.predict_proba, num_features=4)
#print('Document id: %d' % idx)
print('Probability(1) =', c.predict_proba([X2])[0,1])
#print('True class: %s'% class_names[y[idx]])
exp.as_list()
%matplotlib inline
fig = exp.as_pyplot_figure()

exp.show_in_notebook(text=True)
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
from matplotlib import pyplot as plt
documents = X
# Create the Document Term Matrix
count_vectorizer = CountVectorizer(stop_words='english')
count_vectorizer = CountVectorizer()
sparse_matrix = count_vectorizer.fit_transform(documents)

# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.
doc_term_matrix = sparse_matrix.todense()
df = pd.DataFrame(doc_term_matrix, 
                  columns=count_vectorizer.get_feature_names(), 
                  index=['doc0', 'doc1', 'doc2','doc3','doc4'])
df
# Compute Cosine Similarity
from sklearn.metrics.pairwise import cosine_similarity
print(cosine_similarity(df, df))
cosin = cosine_similarity(df, df)
import seaborn as sns;  sns.set()
ax =  sns.heatmap(cosin)
sns.heatmap(cosin, square=True, annot=True,  cbar=True)
plt.show()
distt = 1 - cosine_similarity(df, df)
print(distt)

ax =  sns.heatmap(distt)
sns.heatmap(distt, square=True, annot=True,  cbar=True)
plt.show()
# Calculate the distance between each sample
# You have to think about the metric you use (how to measure similarity) + about the method of clusterization you use (How to group cars)
import pandas as pd
from matplotlib import pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage
import numpy as np

Z = linkage(distt, 'ward')
# Make the dendrogram
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('sample index')
plt.ylabel('distance (Ward)')
dendrogram(Z, labels=df.index, leaf_rotation=90)
plt.show()
dendrogram(Z, labels=df.index, leaf_rotation=0)
dendrogram(Z, labels=df.index)
plt.show()
























 